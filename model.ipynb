{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e19479e-a095-4b30-ad28-9ed5499a3a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbfe5370-eb45-4541-a964-25bd7ec292f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = \"Word\"\n",
    "w2 = \"Word2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0cfbc63-f1f0-4ce3-9ec1-0a64c389a037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nw1,w2 -> [[0.2,0.2,0.4]\\n         [0.1,0.2,0.4]]\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "w1,w2 -> [[0.2,0.2,0.4]\n",
    "         [0.1,0.2,0.4]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f159ad-8b60-4e8e-8e33-a32ffddb8354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural model\n",
    "\n",
    "# 1) Map all words from vocab to a real vector of size m\n",
    "# 2) C matrix -> (len(vocab), m)\n",
    "# 3) all items in C are trainable\n",
    "\n",
    "# Probability function\n",
    "# 1) function g(input sequence of feature vectors(words)) -> maps input sequence to a next possible \n",
    "# word using a conditional probability distribution\n",
    "# output from g -> vector whose ith element estimates probability P(w_t|w_t-1)\n",
    "# g is the neural network\n",
    "\n",
    "# Combine both g and matrix C\n",
    "# 1) function f(sequence_of_vectors(words)) -> g(i, C(w_t-1), C(w_t-n+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41dab39-d863-4763-88ab-5e3869d3cc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f733004-42ea-4fd4-b179-140ea849776b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny = b + Wx + U * tanh(d + Hx)\\n\\nx = concat of all input sequence feature vectors(words)\\nb = biases for W\\nd = biases for H\\nW = direct representation matrix\\nH = hidden layer matrix\\nU = another hidden to output layer matrix\\n\\ny = (Wx + b) + (U * tanh(d+Hx))\\ny =  (1,|V|) +   (1, |V|) \\n     \\ngoes to two different models, addition = (1,|V|) + (1, |V|) = (1,|V|)\\n|V| -> length of vocabuluary\\n\\nthen (1,|V|) -> softmax -> probabilities for each word in vocab\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural model in terms of matrix\n",
    "\"\"\"\n",
    "y = b + Wx + U * tanh(d + Hx)\n",
    "\n",
    "x = concat of all input sequence feature vectors(words)\n",
    "b = biases for W\n",
    "d = biases for H\n",
    "W = direct representation matrix\n",
    "H = hidden layer matrix\n",
    "U = another hidden to output layer matrix\n",
    "\n",
    "y = (Wx + b) + (U * tanh(d+Hx))\n",
    "y =  (1,|V|) +   (1, |V|) \n",
    "     \n",
    "goes to two different models, addition = (1,|V|) + (1, |V|) = (1,|V|)\n",
    "|V| -> length of vocabuluary\n",
    "\n",
    "then (1,|V|) -> softmax -> probabilities for each word in vocab\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee48ba0-8f80-48b0-bc88-57465faf46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep dataset\n",
    "\n",
    "import re\n",
    "\n",
    "words = []\n",
    "\n",
    "with open(\"dataset.txt\",\"r\") as file:\n",
    "    file_content = file.read()\n",
    "    file_content = re.split('; |, |\\*|\\n', file_content)\n",
    "    file_content = re.split(\" \", str(file_content))\n",
    "    words.extend(list(set(file_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc67ce34-7f5c-4ffc-a10d-d07a3e9cc8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87632bb4-a0ec-42a0-8627-ca787db35039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18988"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4457bd91-ea30-46d0-84e4-f6250915a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_i = {}\n",
    "\n",
    "for i in enumerate(words):\n",
    "    word_to_i[i[1]] = i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1e2d561-3a48-44c8-b3a5-b315ee2846ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_to_word = {}\n",
    "for i in enumerate(words):\n",
    "    i_to_word[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7afaecb1-96be-4da1-ae3c-1ce005fd9967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y labels\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in range(len(words)-6):\n",
    "    first_five = words[i:i+5]\n",
    "    next = words[i+5:i+6]\n",
    "\n",
    "    x.append(first_five)\n",
    "    y.append(next[0])\n",
    "    #print(first_five)\n",
    "    #print(next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a250fcc6-9b72-45ee-a457-24d8750d22f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split \n",
    "train_x = x[:int(len(x)*0.8)]\n",
    "test_x = x[len(train_x)-1:]\n",
    "\n",
    "train_y = y[:int(len(y)*0.8)]\n",
    "test_y = y[len(train_y)-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b03b726b-7239-4860-9b56-50fc51f6fc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15185, 15185, 3798, 3798)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x), len(train_y), len(test_x), len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0fff0-c10b-411a-a5d3-bdff8c46c05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9219a26a-74f2-4a28-95d7-c39d5e7c6f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHidden units: 50\\nm: 60\\nn: 5\\ndirect: yes\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model config\n",
    "\"\"\"\n",
    "Hidden units: 50\n",
    "m: 60\n",
    "n: 5\n",
    "direct: yes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8129a1b4-f6d4-45d7-bf42-8db5db618a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer:  torch.Size([300, 50])\n",
      "U layer:  torch.Size([50, 18988])\n",
      "Direct representation layer:  torch.Size([300, 18988])\n",
      "C matrix:  torch.Size([18988, 60])\n"
     ]
    }
   ],
   "source": [
    "# Model \n",
    "# multiple sequence of words as input\n",
    "feature_vector_len = 60\n",
    "hidden_units = 50\n",
    "vocab = len(words)\n",
    "n = 5\n",
    "\n",
    "hidden_layer = torch.randn(n*feature_vector_len, hidden_units, requires_grad=True)\n",
    "U = torch.randn(hidden_units, vocab, requires_grad=True)\n",
    "direct_layer = torch.randn(n*feature_vector_len, vocab, requires_grad=True)\n",
    "C = torch.randn(vocab, feature_vector_len, requires_grad=True)\n",
    "d = torch.tensor(1.0,requires_grad=True)\n",
    "b = torch.tensor(1.0,requires_grad=True)\n",
    "optimizer = optim.SGD([C, direct_layer, hidden_layer, U, d,b], lr=0.01, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "print(\"hidden layer: \", hidden_layer.shape)\n",
    "print(\"U layer: \", U.shape)\n",
    "print(\"Direct representation layer: \", direct_layer.shape)\n",
    "print(\"C matrix: \", C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71c0516f-b106-4cbe-bb0a-4bf55f44e89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence:  [\"sudden',\", \"'“Then\", \"'colour\", \"slow',\", \"'then?\"]\n",
      "next word:  young.\n",
      "feature vectors: torch.Size([1, 300])\n",
      "label:  torch.Size([60])\n",
      "\n",
      "Input @ Hidden layer\n",
      "layer 1 output: torch.Size([1, 50])\n",
      "\n",
      " Output from layer 1 @ Output layer\n",
      "layer 2 output: torch.Size([1, 18988])\n",
      "\n",
      " Input @ Direct rep\n",
      "Direct rep output: torch.Size([1, 18988])\n",
      "\n",
      "Final output - layer 2 + direct: torch.Size([1, 18988])\n",
      "\n",
      "softmax output: torch.Size([1, 18988])\n",
      "\n",
      "prediction: nail',\n",
      "81.305908203125\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "\n",
    "tanh = nn.Tanh()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "CLE = nn.CrossEntropyLoss()\n",
    "\n",
    "def get_feature_vector(word):\n",
    "    index = word_to_i[word]\n",
    "    return C[index]\n",
    "    \n",
    "print(\"input sequence: \",train_x[0])\n",
    "print(\"next word: \",train_y[0])\n",
    "\n",
    "feature_vectors = torch.stack([get_feature_vector(word) for word in train_x[0]])\n",
    "feature_vectors = torch.cat(torch.unbind(feature_vectors), dim=0)\n",
    "feature_vectors = feature_vectors.view(1,-1)\n",
    "print(\"feature vectors:\", feature_vectors.shape)\n",
    "\n",
    "label = get_feature_vector(train_y[0])\n",
    "print(\"label: \", label.shape)\n",
    "\n",
    "# Hidden layer\n",
    "\n",
    "layer_1_output = torch.matmul(feature_vectors, hidden_layer) + d \n",
    "print(\"\\nInput @ Hidden layer\")\n",
    "print(\"layer 1 output:\", layer_1_output.shape)\n",
    "\n",
    "layer_1_output = tanh(layer_1_output)\n",
    "\n",
    "# Hidden to output layer\n",
    "layer_2_output = torch.matmul(layer_1_output, U)\n",
    "print(\"\\n Output from layer 1 @ Output layer\")\n",
    "print(\"layer 2 output:\", layer_2_output.shape)\n",
    "\n",
    "\n",
    "# Direct representation\n",
    "\n",
    "direct_output = torch.matmul(feature_vectors, direct_layer) + b\n",
    "print(\"\\n Input @ Direct rep\")\n",
    "print(\"Direct rep output:\", direct_output.shape)\n",
    "\n",
    "# Concat\n",
    "final_output = layer_2_output + direct_output\n",
    "print(\"\\nFinal output - layer 2 + direct:\", final_output.shape)\n",
    "\n",
    "# Softmax\n",
    "prob = softmax(final_output)\n",
    "print(\"\\nsoftmax output:\", prob.shape)\n",
    "\n",
    "answer = torch.argmax(prob)\n",
    "print(\"\\nprediction:\", i_to_word[answer.item()])\n",
    "\n",
    "# Loss\n",
    "loss = CLE(final_output, torch.tensor([word_to_i[train_y[0]]]))\n",
    "print(loss.item())\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "df6c2358-cb5d-4662-a412-4a2573334b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(word):\n",
    "    index = word_to_i[word]\n",
    "    return C[index]\n",
    "    \n",
    "def get_batch(x,y, size):\n",
    "    \n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    \n",
    "    # Get list of 50 random indexes\n",
    "    res = random.sample(range(0, len(x)), size)\n",
    "    \n",
    "    for i in res:\n",
    "        # Get feature vectors for all 5 words, combined into one vector\n",
    "        feature_vectors = torch.stack([get_feature_vector(word) for word in x[i]])\n",
    "        feature_vectors = torch.cat(torch.unbind(feature_vectors), dim=0)\n",
    "        #feature_vectors = feature_vectors.view(1,-1) # [1,n*m]\n",
    "        batch_x.append(feature_vectors)\n",
    "        batch_y.append(word_to_i[y[i]])\n",
    "        \n",
    "    batch_x = torch.stack(batch_x)\n",
    "    batch_y = torch.tensor(batch_y)\n",
    "    # Y label doesn't require feature vectors, loss is calculated directly using index\n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b3e55550-185e-4009-ab09-ad216b290016",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y = get_batch(train_x,train_y,len(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bd0b890b-58a8-42b8-aaa2-1baeb0d78053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15185, 300]), torch.Size([15185]))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.shape, batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a619fcd1-b2d8-454a-a4d1-44b141558108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 69.13443756103516\n",
      "Loss: 68.22632598876953\n",
      "Loss: 71.65194702148438\n",
      "Loss: 70.70344543457031\n",
      "Loss: 76.0293197631836\n",
      "Loss: 70.72949981689453\n",
      "Loss: 70.98185729980469\n",
      "Loss: 74.07401275634766\n",
      "Loss: 71.87630462646484\n",
      "Loss: 73.25398254394531\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "tanh = nn.Tanh()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "CLE = nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    loss = 0\n",
    "    batch_x,batch_y = get_batch(train_x,train_y, 50)\n",
    "\n",
    "    # Hidden layer\n",
    "    layer_1_output = torch.matmul(batch_x, hidden_layer) + d\n",
    "    layer_1_output = tanh(layer_1_output)\n",
    "    \n",
    "    # Hidden to output layer\n",
    "    layer_2_output = torch.matmul(layer_1_output, U)\n",
    "\n",
    "    # Direct representation\n",
    "    direct_output = torch.matmul(batch_x, direct_layer) + b\n",
    "\n",
    "    # Concat\n",
    "    final_output = layer_2_output + direct_output\n",
    "    #print(final_output.shape)\n",
    "\n",
    "    # Loss\n",
    "    loss = CLE(final_output, batch_y)\n",
    "    print(\"Loss:\",loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "24a518aa-d4e6-4c64-8d32-50bbce154cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence: [\"sudden',\", \"'“Then\", \"'colour\", \"slow',\", \"'then?\"]\n",
      "answer: young.\n",
      "prediction: late,”\n",
      "\n",
      "\n",
      "sequence: [\"'“Then\", \"'colour\", \"slow',\", \"'then?\", 'young.']\n",
      "answer: column,',\n",
      "prediction: handy\n",
      "\n",
      "\n",
      "sequence: [\"'colour\", \"slow',\", \"'then?\", 'young.', \"column,',\"]\n",
      "answer: “Think\n",
      "prediction: happy\n",
      "\n",
      "\n",
      "sequence: [\"slow',\", \"'then?\", 'young.', \"column,',\", '“Think']\n",
      "answer: 'sunburnt\n",
      "prediction: warm\n",
      "\n",
      "\n",
      "sequence: [\"'then?\", 'young.', \"column,',\", '“Think', \"'sunburnt\"]\n",
      "answer: foretold',\n",
      "prediction: kindly',\n",
      "\n",
      "\n",
      "sequence: ['young.', \"column,',\", '“Think', \"'sunburnt\", \"foretold',\"]\n",
      "answer: ha’\n",
      "prediction: brow\n",
      "\n",
      "\n",
      "sequence: [\"column,',\", '“Think', \"'sunburnt\", \"foretold',\", 'ha’']\n",
      "answer: top-hat\n",
      "prediction: serving\n",
      "\n",
      "\n",
      "sequence: ['“Think', \"'sunburnt\", \"foretold',\", 'ha’', 'top-hat']\n",
      "answer: me.\n",
      "prediction: heartily\n",
      "\n",
      "\n",
      "sequence: [\"'sunburnt\", \"foretold',\", 'ha’', 'top-hat', 'me.']\n",
      "answer: 'unbuttoned\n",
      "prediction: wisely,”\n",
      "\n",
      "\n",
      "sequence: [\"foretold',\", 'ha’', 'top-hat', 'me.', \"'unbuttoned\"]\n",
      "answer: sensations',\n",
      "prediction: 'successfully\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "def get_predictions(x,y):\n",
    "    batch_x,batch_y = get_batch(x,y,len(x))\n",
    "    \n",
    "    layer_1_output = torch.matmul(batch_x, hidden_layer) + d\n",
    "    layer_1_output = tanh(layer_1_output)\n",
    "    \n",
    "    # Hidden to output layer\n",
    "    layer_2_output = torch.matmul(layer_1_output, U)\n",
    "\n",
    "    # Direct representation\n",
    "    direct_output = torch.matmul(batch_x, direct_layer) + b\n",
    "\n",
    "    # Concat\n",
    "    final_output = layer_2_output + direct_output\n",
    "    #print(final_output.shape)\n",
    "    \n",
    "    # Softmax\n",
    "    prob = softmax(final_output)\n",
    "    for i in range(prob.shape[0]):\n",
    "        print(\"sequence:\", x[i])\n",
    "        print(\"answer:\", y[i])\n",
    "        answer = torch.argmax(prob[i])\n",
    "        print(\"prediction:\", i_to_word[answer.item()])\n",
    "        print(\"\\n\")\n",
    "\n",
    "get_predictions(train_x[:10], train_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f33c0-46b5-4827-9d70-bc30c67b3428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
